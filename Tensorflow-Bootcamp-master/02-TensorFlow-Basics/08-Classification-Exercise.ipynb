{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the Directions in Bold. If you get stuck, check out the solutions lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census = pd.read_csv('census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, you'll need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s. This might be hard if you aren't very familiar with pandas, so feel free to take a peek at the solutions for this part.**\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['income_bracket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_fix(label):\n",
    "    if label == ' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census['income_bracket'] = census['income_bracket'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = census.drop('income_bracket', axis = 1)\n",
    "y_labels = census['income_bracket']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_labels,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(\"gender\", [\"Female\", \"Male\"])\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket(\"marital_status\", hash_bucket_size=1000)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket(\"relationship\", hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket(\"education\", hash_bucket_size=1000)\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket(\"workclass\", hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = [gender,occupation,marital_status,relationship,education,workclass,native_country,\n",
    "            age,education_num,capital_gain,capital_loss,hours_per_week]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x = X_train, y = y_train, batch_size=100, num_epochs = None, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/zz/zyxvpxvq6csfxvn_n0002d4m000l95/T/tmp0id2aqii\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': 1, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_model_dir': '/var/folders/zz/zyxvpxvq6csfxvn_n0002d4m000l95/T/tmp0id2aqii', '_log_step_count_steps': 100, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/zz/zyxvpxvq6csfxvn_n0002d4m000l95/T/tmp0id2aqii/model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into /var/folders/zz/zyxvpxvq6csfxvn_n0002d4m000l95/T/tmp0id2aqii/model.ckpt.\n",
      "INFO:tensorflow:step = 5001, loss = 29.0375\n",
      "INFO:tensorflow:global_step/sec: 178.354\n",
      "INFO:tensorflow:step = 5101, loss = 34.2161 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.196\n",
      "INFO:tensorflow:step = 5201, loss = 50.578 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.45\n",
      "INFO:tensorflow:step = 5301, loss = 46.5775 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.006\n",
      "INFO:tensorflow:step = 5401, loss = 98.4301 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.312\n",
      "INFO:tensorflow:step = 5501, loss = 168.064 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.603\n",
      "INFO:tensorflow:step = 5601, loss = 198.014 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.272\n",
      "INFO:tensorflow:step = 5701, loss = 107.71 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.681\n",
      "INFO:tensorflow:step = 5801, loss = 29.6237 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 194\n",
      "INFO:tensorflow:step = 5901, loss = 32.2121 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.55\n",
      "INFO:tensorflow:step = 6001, loss = 31.7492 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.299\n",
      "INFO:tensorflow:step = 6101, loss = 35.3092 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.327\n",
      "INFO:tensorflow:step = 6201, loss = 31.8615 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.533\n",
      "INFO:tensorflow:step = 6301, loss = 90.4208 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.866\n",
      "INFO:tensorflow:step = 6401, loss = 184.934 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.659\n",
      "INFO:tensorflow:step = 6501, loss = 159.245 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.148\n",
      "INFO:tensorflow:step = 6601, loss = 33.0919 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.082\n",
      "INFO:tensorflow:step = 6701, loss = 56.1413 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.175\n",
      "INFO:tensorflow:step = 6801, loss = 36.7695 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.743\n",
      "INFO:tensorflow:step = 6901, loss = 57.0099 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.472\n",
      "INFO:tensorflow:step = 7001, loss = 28.8452 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.282\n",
      "INFO:tensorflow:step = 7101, loss = 32.1039 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.124\n",
      "INFO:tensorflow:step = 7201, loss = 55.2369 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.105\n",
      "INFO:tensorflow:step = 7301, loss = 22.8868 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.625\n",
      "INFO:tensorflow:step = 7401, loss = 44.9845 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.052\n",
      "INFO:tensorflow:step = 7501, loss = 37.6045 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.363\n",
      "INFO:tensorflow:step = 7601, loss = 42.6449 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.134\n",
      "INFO:tensorflow:step = 7701, loss = 71.9194 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.976\n",
      "INFO:tensorflow:step = 7801, loss = 36.9074 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.017\n",
      "INFO:tensorflow:step = 7901, loss = 49.4223 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.417\n",
      "INFO:tensorflow:step = 8001, loss = 35.3192 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.958\n",
      "INFO:tensorflow:step = 8101, loss = 34.9079 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.354\n",
      "INFO:tensorflow:step = 8201, loss = 37.9519 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.919\n",
      "INFO:tensorflow:step = 8301, loss = 61.7393 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.774\n",
      "INFO:tensorflow:step = 8401, loss = 34.9427 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.86\n",
      "INFO:tensorflow:step = 8501, loss = 30.6336 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.846\n",
      "INFO:tensorflow:step = 8601, loss = 45.745 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.535\n",
      "INFO:tensorflow:step = 8701, loss = 25.5319 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.846\n",
      "INFO:tensorflow:step = 8801, loss = 71.6456 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.676\n",
      "INFO:tensorflow:step = 8901, loss = 46.5426 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.349\n",
      "INFO:tensorflow:step = 9001, loss = 41.3491 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.406\n",
      "INFO:tensorflow:step = 9101, loss = 29.9615 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.248\n",
      "INFO:tensorflow:step = 9201, loss = 325.106 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.207\n",
      "INFO:tensorflow:step = 9301, loss = 31.0577 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.371\n",
      "INFO:tensorflow:step = 9401, loss = 23.3838 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.077\n",
      "INFO:tensorflow:step = 9501, loss = 37.1028 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.737\n",
      "INFO:tensorflow:step = 9601, loss = 47.9369 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.024\n",
      "INFO:tensorflow:step = 9701, loss = 27.432 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.597\n",
      "INFO:tensorflow:step = 9801, loss = 34.1406 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.988\n",
      "INFO:tensorflow:step = 9901, loss = 70.4347 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.957\n",
      "INFO:tensorflow:step = 10001, loss = 42.2681 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.012\n",
      "INFO:tensorflow:step = 10101, loss = 26.0302 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.155\n",
      "INFO:tensorflow:step = 10201, loss = 43.1248 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.42\n",
      "INFO:tensorflow:step = 10301, loss = 28.7804 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.871\n",
      "INFO:tensorflow:step = 10401, loss = 29.0645 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.984\n",
      "INFO:tensorflow:step = 10501, loss = 28.4007 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.295\n",
      "INFO:tensorflow:step = 10601, loss = 71.096 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.452\n",
      "INFO:tensorflow:step = 10701, loss = 35.2928 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.864\n",
      "INFO:tensorflow:step = 10801, loss = 220.083 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.97\n",
      "INFO:tensorflow:step = 10901, loss = 77.5097 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.257\n",
      "INFO:tensorflow:step = 11001, loss = 43.2943 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.611\n",
      "INFO:tensorflow:step = 11101, loss = 64.7042 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.45\n",
      "INFO:tensorflow:step = 11201, loss = 48.4409 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.674\n",
      "INFO:tensorflow:step = 11301, loss = 50.638 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.974\n",
      "INFO:tensorflow:step = 11401, loss = 68.8152 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.834\n",
      "INFO:tensorflow:step = 11501, loss = 43.9145 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.29\n",
      "INFO:tensorflow:step = 11601, loss = 30.1545 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.779\n",
      "INFO:tensorflow:step = 11701, loss = 42.0973 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.851\n",
      "INFO:tensorflow:step = 11801, loss = 31.042 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.173\n",
      "INFO:tensorflow:step = 11901, loss = 43.2961 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.313\n",
      "INFO:tensorflow:step = 12001, loss = 70.5282 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.294\n",
      "INFO:tensorflow:step = 12101, loss = 165.406 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.588\n",
      "INFO:tensorflow:step = 12201, loss = 39.4264 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.921\n",
      "INFO:tensorflow:step = 12301, loss = 47.0665 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.987\n",
      "INFO:tensorflow:step = 12401, loss = 39.5357 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.962\n",
      "INFO:tensorflow:step = 12501, loss = 36.8101 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.346\n",
      "INFO:tensorflow:step = 12601, loss = 27.498 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.256\n",
      "INFO:tensorflow:step = 12701, loss = 39.1479 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.411\n",
      "INFO:tensorflow:step = 12801, loss = 36.2639 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.362\n",
      "INFO:tensorflow:step = 12901, loss = 101.121 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.902\n",
      "INFO:tensorflow:step = 13001, loss = 81.6379 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.783\n",
      "INFO:tensorflow:step = 13101, loss = 54.4983 (0.505 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 199.868\n",
      "INFO:tensorflow:step = 13201, loss = 31.5616 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.608\n",
      "INFO:tensorflow:step = 13301, loss = 59.5757 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.974\n",
      "INFO:tensorflow:step = 13401, loss = 33.9873 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.252\n",
      "INFO:tensorflow:step = 13501, loss = 28.8344 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.273\n",
      "INFO:tensorflow:step = 13601, loss = 34.9857 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.845\n",
      "INFO:tensorflow:step = 13701, loss = 46.9045 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.228\n",
      "INFO:tensorflow:step = 13801, loss = 41.2131 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.974\n",
      "INFO:tensorflow:step = 13901, loss = 34.5866 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.517\n",
      "INFO:tensorflow:step = 14001, loss = 27.1783 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.599\n",
      "INFO:tensorflow:step = 14101, loss = 52.4107 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.7\n",
      "INFO:tensorflow:step = 14201, loss = 30.3698 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.02\n",
      "INFO:tensorflow:step = 14301, loss = 31.8936 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.839\n",
      "INFO:tensorflow:step = 14401, loss = 116.957 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.739\n",
      "INFO:tensorflow:step = 14501, loss = 36.0502 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.783\n",
      "INFO:tensorflow:step = 14601, loss = 36.8876 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.198\n",
      "INFO:tensorflow:step = 14701, loss = 23.1896 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.814\n",
      "INFO:tensorflow:step = 14801, loss = 41.067 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.956\n",
      "INFO:tensorflow:step = 14901, loss = 107.595 (0.500 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into /var/folders/zz/zyxvpxvq6csfxvn_n0002d4m000l95/T/tmp0id2aqii/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 83.3397.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x12247a0f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn = input_func, steps = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x = X_test, batch_size = len(X_test), shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/zz/zyxvpxvq6csfxvn_n0002d4m000l95/T/tmp0id2aqii/model.ckpt-15000\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(pred_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([0]),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'logistic': array([ 0.20098951], dtype=float32),\n",
       " 'logits': array([-1.38012123], dtype=float32),\n",
       " 'probabilities': array([ 0.79901046,  0.20098953], dtype=float32)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89      7436\n",
      "          1       0.69      0.46      0.55      2333\n",
      "\n",
      "avg / total       0.81      0.82      0.81      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
